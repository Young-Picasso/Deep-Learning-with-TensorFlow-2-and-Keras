{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we add two hidden layers in hopes of improving the performance over the previous model which did not have hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 train samples\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Network and training\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Load MNIST dataset\n",
    "# Labels have one-hot representation\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# X_train is 60,000 rows of 28x28 values, we flatten the images to vectors of length 784\n",
    "RESHAPED = 784\n",
    "\n",
    "X_train = X_train.reshape(60_000, RESHAPED)\n",
    "X_test = X_test.reshape(10_000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalize inputs to range [0, 1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(f'{X_train.shape[0]} train samples')\n",
    "print(f'{X_test.shape[0]} train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_layer_1 (Dense)       (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_layer_2 (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_layer_3 (Dense)       (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Labels have one-hot representation\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED,), name='dense_layer_1', activation='relu'))\n",
    "model.add(keras.layers.Dense(N_HIDDEN, name='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dense(NB_CLASSES, name='dense_layer_3', activation='softmax'))\n",
    "\n",
    "# Summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3573 - accuracy: 0.9005 - val_loss: 0.1657 - val_accuracy: 0.9524\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9575 - val_loss: 0.1341 - val_accuracy: 0.9590\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9710 - val_loss: 0.0994 - val_accuracy: 0.9685\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9785 - val_loss: 0.0954 - val_accuracy: 0.9707\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9830 - val_loss: 0.0954 - val_accuracy: 0.9703\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.0843 - val_accuracy: 0.9737\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.0852 - val_accuracy: 0.9741\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9925 - val_loss: 0.0933 - val_accuracy: 0.9727\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0889 - val_accuracy: 0.9743\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0895 - val_accuracy: 0.9750\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1109 - val_accuracy: 0.9700\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0940 - val_accuracy: 0.9779\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0966 - val_accuracy: 0.9748\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.1173 - val_accuracy: 0.9717\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0977 - val_accuracy: 0.9768\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1055 - val_accuracy: 0.9768\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.1030 - val_accuracy: 0.9758\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.1104 - val_accuracy: 0.9757\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.1076 - val_accuracy: 0.9780\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1185 - val_accuracy: 0.9748\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1155 - val_accuracy: 0.9763\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1368 - val_accuracy: 0.9724\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.1252 - val_accuracy: 0.9758\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1319 - val_accuracy: 0.9747\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1422 - val_accuracy: 0.9722\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1061 - val_accuracy: 0.9791\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1342 - val_accuracy: 0.9740\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.1380 - val_accuracy: 0.9735\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1149 - val_accuracy: 0.9773\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1131 - val_accuracy: 0.9790\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1258 - val_accuracy: 0.9776\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.1401 - val_accuracy: 0.9749\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1295 - val_accuracy: 0.9783\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1175 - val_accuracy: 0.9808\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 7.6838e-04 - accuracy: 0.9998 - val_loss: 0.1111 - val_accuracy: 0.9805\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.0646e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9811\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 6.2515e-05 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9809\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 5.0170e-05 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9811\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 4.1392e-05 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9812\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.5970e-05 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9808\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 3.0649e-05 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9811\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 2.6345e-05 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9809\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 2.2559e-05 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9812\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.9823e-05 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9812\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.6678e-05 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9807\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.4950e-05 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9811\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.3020e-05 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9812\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.1119e-05 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9806\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 9.3329e-06 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9810\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 8.1698e-06 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb85509320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 779us/step - loss: 0.1380 - accuracy: 0.9806\n",
      "Test accuracy: 0.9805999994277954\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our test accuracy improved from 92.55% in the \"Defining a simple neural network in TensorFlow 2.0\" to 98.05% just by adding two hidden layers. Next, we will implement dropout, a form of regularization to try and improve this further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningUsingTensorFlowCookbook",
   "language": "python",
   "name": "machinelearningusingtensorflowcookbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
